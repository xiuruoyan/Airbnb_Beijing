{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from re import sub\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "source_path = cwd + '/source//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "calendar = pd.read_csv(source_path + '/calendar.csv')\n",
    "df_list = pd.read_csv(source_path + '/listings.csv')\n",
    "listings_detail = pd.read_csv(source_path + '/listings_detail.csv')\n",
    "#neighbourhoods = pd.read_csv(cwd + '/neighbourhoods.csv')\n",
    "reviews = pd.read_csv(source_path + '/reviews_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list['neighbourhood'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(listings_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list['neighbourhood'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list['neighbourhood'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is score important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first step: clean data and deal with Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = 'availability_30'\n",
    "df = listings_detail[['neighbourhood_cleansed', 'room_type', 'price',\n",
    "                      'review_scores_rating', 'reviews_per_month',\n",
    "                      'number_of_reviews_ltm', 'property_type',\n",
    "                        response]]\n",
    "# df = listings_detail[['room_type', 'price',\n",
    "#                         'review_scores_rating', 'reviews_per_month',\n",
    "#                         'availability_365']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['availability_score'] = np.where(df[response]==0, 30, 30-df[response])\n",
    "df.drop([response], axis=1, inplace=True)\n",
    "response = 'availability_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_to_float(row):\n",
    "    '''\n",
    "    INPUT:\n",
    "    row - pandas dataframe with 'price'\n",
    "    \n",
    "    OUTPUT:\n",
    "    the true value of price\n",
    "    '''\n",
    "    f = row['price']\n",
    "    return float(sub(r'[^\\d.]', '', f))\n",
    "\n",
    "df['price_value'] = df.apply(currency_to_float, axis=1)\n",
    "df.drop(['price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['neighbourhood_cleansed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping where the availability_30 has missing values\n",
    "df  = df.dropna(subset=[response], axis=0)\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull a list of the column names of the categorical variables\n",
    "cat_df = df.select_dtypes(include=['object'])\n",
    "cat_cols_lst = cat_df.columns\n",
    "\n",
    "df_new = create_dummy_df(df, cat_cols_lst, dummy_na=False)\n",
    "\n",
    "# Show shape to assure it has a shape of (5009, 11938)\n",
    "print(df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['price_value']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with missing values and create model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean function\n",
    "# fill none value with mean.\n",
    "fill_mean = lambda col: col.fillna(col.mean())\n",
    "# Fill the mean\n",
    "fill_df = df_new.apply(fill_mean, axis=0)\n",
    "\n",
    "#Split into explanatory and response variables\n",
    "X = fill_df.drop([response], axis=1)\n",
    "y = fill_df[response]\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42) \n",
    "\n",
    "lm_model = LinearRegression(normalize=\\False) # Instantiate\n",
    "lm_model.fit(X_train, y_train) #Fit\n",
    " \n",
    "#Predict using your model\n",
    "y_test_preds = lm_model.predict(X_test)\n",
    "y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "# #Score using your model\n",
    "test_score = r2_score(y_test, y_test_preds)\n",
    "train_score = r2_score(y_train, y_train_preds)\n",
    "\n",
    "print(\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step 2: find influence on score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = listings_detail[[#'id',\n",
    "                          'review_scores_rating', 'review_scores_accuracy', \n",
    "                          'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                          'review_scores_communication', 'review_scores_location',\n",
    "                          'review_scores_value']]\n",
    "scores.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find correlations between related variables\n",
    "corr = scores.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(scores.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(scores.columns)\n",
    "ax.set_yticklabels(scores.columns)\n",
    "plt.show()\n",
    "fig.savefig('correlation.png', optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step three Dig into comments\n",
    "\n",
    "reviews = reviews.dropna(subset=['comments'])\n",
    "reviews.info()\n",
    "\n",
    "\n",
    "def clean_content(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with 'comments'\n",
    "    \n",
    "    OUTPUT:\n",
    "    cleaned content without symbols\n",
    "    '''\n",
    "    # filter out symbols\n",
    "    f = df['comments']\n",
    "#     r1 = u'[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+'\n",
    "    r1 = u'[0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘’！[\\\\]^_`{|}~]+'\n",
    "    return re.sub(r1,'', f).replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "reviews['cleaned_comments'] = reviews.apply(clean_content, axis=1)\n",
    "\n",
    "\n",
    "def is_Chinese(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with 'comments'\n",
    "    \n",
    "    OUTPUT:\n",
    "    bool showing if the input is in Chinese\n",
    "    '''\n",
    "    f = df['comments']\n",
    "    HZPattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "    return HZPattern.search(f)\n",
    "reviews['is_Chinese'] = reviews.apply(is_Chinese, axis=1)\n",
    "\n",
    "reviews_English = reviews[reviews['is_Chinese'].isnull()]\n",
    "\n",
    "\n",
    "neighbourhood_id = df_list[['id', 'neighbourhood']]\n",
    "reviews_English = reviews_English.merge(neighbourhood_id, how='left', left_on = 'listing_id', right_on = 'id')\n",
    "\n",
    "text = \" \".join(review for review in reviews_English['cleaned_comments'])\n",
    "# Create stopword list:\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('english')\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"also\", \"room\", \"apartment\", \"posting\", \"canceled\",\"reservation\", \"host\", \"Beijing\", \"stay\",\n",
    "                 \"arrival\", \"days\", \"house\", \"good\", \"nice\", \"one\", \"really\", \"area\", \"even\"])\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
